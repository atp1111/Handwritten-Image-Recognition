---
title: "project"
format: html
---

```{r}
#################################################
## Stat 6560  Final Project
## Autumn 2025
#################################################

library(MASS)   # load library MASS

# read data files --------------------------------

data.7 <- read.csv("train.7.txt", header = F)
data.7 <- as.matrix(data.7)
data.9 <- read.csv("train.9.txt", header = F)
data.9 <- as.matrix(data.9)

# > dim(data.7) # data set dimension
# [1] 645 256
# > dim(data.9)
# [1] 644 256

# visualize the digit images ---------------------
# note: each row corresponds to one observation or a digit
 
# For example, pick the first observation of "7"
i <- 1 

# turn a 256 row vector into a 16x16 matrix 
img <- matrix(as.vector(data.7[i,]), nrow = 16, ncol=16)

# display the matrix in grayscale
image(img[,16:1], col=gray((32:0)/32), axes=F)

# "16:1" reverses the column order for proper display of the image.
# grayscale "(32:0)/32" maps low pixel values to dark shades.


# since we need to visualize vectors as images many times in this analysis,
# define a function called "digit.image" which takes a 256 vector as input
# and displays the corresponding 16x16 matrix as a grayscale image:

digit.image <- function(x)
               { img <- matrix(as.vector(x), nrow = 16, ncol=16) 
               	 image(img[,16:1], col=gray((32:0)/32), axes=F)
               	 box(col=3)
               	}

# try the new function!
digit.image(data.7[i,])

# visualize the first five "7" and the first five "9" images
par(mfrow=c(2,5), omi=rep(0,4), mar=rep(0.2,4)) # 2x5 display
for (i in 1:5)
{ digit.image(data.7[i,]) }
for (i in 1:5)
{ digit.image(data.9[i,]) }

par(mfrow=c(1,1))

# split data into a training set and a test set --------------

data.7.train <- data.7[1:400,]
data.7.test <- data.7[401:645,]

data.9.train <- data.9[1:400,]
data.9.test <- data.9[401:644,]

# training data
data.train <- rbind(data.7.train, data.9.train)
# > dim(data.train)
# [1] 800 256
label.train <- c(rep(7,400), rep(9,400)) # class labels for training data

# test data
data.test <- rbind(data.7.test, data.9.test)
# > dim(data.test)
# [1] 489 256
label.test <- c(rep(7,245), rep(9,244)) # class labels for test data


# PCA  -----------------------





# LDA  -----------------------
col.sd <- apply(data.train, 2, sd)  # compute columnwise standard deviation
# > sum(col.sd==0)   # 18 variables with zero SD!
# [1] 18

# > summary(col.sd)
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.0000  0.1676  0.5481  0.4588  0.7320  0.8543 

# visualize col.sd
digit.image(col.sd)

# let's use only those variables with SD>0.2
col.ind <- (1:256)[col.sd>0.2]  # this contains the indices of variables with SD>0.2 
lda.79 <- lda(data.train[,col.ind], label.train) # lda(x, grouping)

LD1 <- rep(0,256)
LD1[col.ind] <- lda.79$scaling   # linear discriminant coefficients as a 256 dim vector
digit.image(LD1)
digit.image(abs(LD1)) # visualize the absolute values of the coefficients
```

```{r}
#PCA PART 1A
#We use prcomp (SVD-based PCA). 
# Note: We generally do NOT scale pixel data (scale=FALSE) because the variables 
# are in the same units (intensity), and scaling would amplify noise in dark background pixels.
pca.7 <- prcomp(data.7.train, center = TRUE, scale. = FALSE)

# Extract components
mu.7 <- pca.7$center       # The mean vector (x-bar)
evals.7 <- (pca.7$sdev)^2  # Eigenvalues (variances)
evecs.7 <- pca.7$rotation  # Eigenvectors (loadings/directions)
scores.7 <- pca.7$x        # PC scores

# 2. Visualize the Average Image -----------------------------------------------
par(mfrow=c(1,1))
digit.image(mu.7)
title(main = "Average Image of '7'")

# 3. Visualize Synthetic Images (Mean + c * Eigenvector) -----------------------
# Instruction: Visualize variation along first few PCs using x_bar + c * e

# Helper function to plot the sequence of variations
# We look at PC1, PC2, and PC3
# range of c: We use quantiles of the standard deviation (sqrt(eigenvalue))
plot_pc_variation <- function(pc_index, sd_val, mean_vec, eigen_mat) {
  # c values: -2SD, -1SD, Mean, +1SD, +2SD
  c_vals <- c(-2, -1, 0, 1, 2) * sd_val
  
  for (c in c_vals) {
    # Formula: x_bar + c * e
    synthetic_vec <- mean_vec + (c * eigen_mat[, pc_index])
    digit.image(synthetic_vec)
  }
}

par(mfrow=c(5,5), mar=c(0.1, 0.1, 0.1, 0.1))
for(i in 1:5) { plot_pc_variation(i, pca.7$sdev[i], mu.7, evecs.7) }

# 4. Identify Typical and Atypical Images --------------------------------------
# "Typical" = close to the mean (scores near 0)
# "Atypical" = far from the mean (high magnitude scores)

# Let's look at the distance from center in the PC1-PC2 plane
dist_from_center <- sqrt(scores.7[,1]^2 + scores.7[,2]^2)

# Find indices
idx_typical <- order(dist_from_center)[1:5]            # Closest to 0
idx_atypical <- order(dist_from_center, decreasing=T)[1:5] # Furthest from 0

# Visualize Typical
par(mfrow=c(2,5), mar=c(1,1,1,1))
for(i in idx_typical) {
  digit.image(data.7.train[i,])
  box(col="green", lwd=2) # Green box for typical
}
mtext("Typical '7's", side=3, line=-2, outer=TRUE)

# Visualize Atypical
for(i in idx_atypical) {
  digit.image(data.7.train[i,])
  box(col="red", lwd=2) # Red box for atypical
}
mtext("Atypical '7's", side=3, line=-15, outer=TRUE)

# 5. Adequacy of Representation (Scree Plot) -----------------------------------
# ==============================================================================
# Better Scree Plot for Part 1(a) - Determining Adequacy
# ==============================================================================

# 5. Adequacy of Representation (Dual Scree Plots) -----------------------------

# --- Plot A: The Elbow Method (Visual Structure) ---
# We look at the first 30 components to see the "bend" clearly
par(mfrow=c(1,2)) # Split screen: Left = Bar, Right = Line

# Bar Plot
barplot(evals.7[1:30], 
        main="Scree Plot (Variances)", 
        names.arg=1:30, 
        col="gray", border=NA,
        ylab="Variance", xlab="PC #")

# Line Plot (The one you asked for)
plot(evals.7[1:30], 
     type="b", pch=19, col="black",
     main="Scree Plot (The Elbow)",
     ylab="Eigenvalue (Variance)",
     xlab="PC #")
grid()
```

```{r}
#PCA PART 1B 
# 1. Apply PCA on data.9.train -------------------------------------------------
# Ensure you are using the '9' training data here
pca.9 <- prcomp(data.9.train, center = TRUE, scale. = FALSE)

# Extract components for Digit 9
mu.9 <- pca.9$center       # The mean vector for 9
evals.9 <- (pca.9$sdev)^2  # Eigenvalues
evecs.9 <- pca.9$rotation  # Eigenvectors
scores.9 <- pca.9$x        # PC scores

# 2. Visualize the Average Image of "9" ----------------------------------------
par(mfrow=c(1,1))
digit.image(mu.9)
title(main = "Average Image of '9'")

# 3. Visualize Synthetic Images (Mean + c * Eigenvector) -----------------------
# Re-using the plot_pc_variation function we defined in Part 1(a)

par(mfrow=c(5,5), mar=c(0.1, 0.1, 0.1, 0.1), oma=c(0, 2, 2, 0)) 

# Loop through PC 1 to 5
for (i in 1:5) {
  # 1. Plot the row of 5 images using your helper function
  plot_pc_variation(i, pca.9$sdev[i], mu.9, evecs.9)
  
  # 2. Add a label to the left of the row
  # 'outer=TRUE' places it in the margin we created with 'oma'
  # The 'at' calculation centers the label on the correct row
  mtext(paste("PC", i), side=2, line=0.5, outer=TRUE, 
        at=1 - (i-0.5)/5, las=1, cex=0.8)
}

# Add a main title at the top
mtext("Variations along PC 1 to 5 (Digit 9)", side=3, line=0.5, outer=TRUE, cex=1.2)


# 4. Identify Typical and Atypical "9"s ----------------------------------------
# Calculate distance from center for '9's
dist_9 <- sqrt(scores.9[,1]^2 + scores.9[,2]^2)

# Find indices
idx_typical_9 <- order(dist_9)[1:5]            # Smallest distance
idx_atypical_9 <- order(dist_9, decreasing=T)[1:5] # Largest distance

# Visualize Typical 9s (Green Box)
par(mfrow=c(2,5), mar=c(1,1,1,1))
for(i in idx_typical_9) {
  digit.image(data.9.train[i,])
  box(col="green", lwd=2)
}
mtext("Typical '9's", side=3, line=-2, outer=TRUE)

# Visualize Atypical 9s (Red Box)
for(i in idx_atypical_9) {
  digit.image(data.9.train[i,])
  box(col="red", lwd=2)
}
mtext("Atypical '9's", side=3, line=-15, outer=TRUE)


# 5. Adequacy (Scree Plot for 9) -----------------------------------------------
par(mfrow=c(1,2)) # Split screen: Left = Bar, Right = Line

# 1. Bar Plot (Variances)
barplot(evals.9[1:30], 
        main="Scree (Var) - Digit 9", 
        names.arg=1:30, 
        col="gray", border=NA,
        ylab="Variance", xlab="PC #")

# 2. Line Plot (The Elbow)
plot(evals.9[1:30], 
     type="b", pch=19, col="black",
     main="Scree (Elbow) - Digit 9",
     ylab="Eigenvalue (Variance)",
     xlab="PC #")
grid()
```

```{r}
#PCA PART 1C 
# 1. Apply PCA on the Combined Data (data.train) -------------------------------
# This dataset has 800 rows (400 "7"s and 400 "9"s)
pca.combined <- prcomp(data.train, center = TRUE, scale. = FALSE)

# Extract results for combined data
mu.comb <- pca.combined$center       # The "Ghostly" Mean
evecs.comb <- pca.combined$rotation  # Directions of variation
scores.comb <- pca.combined$x        # Scores for each image
evals.comb <- pca.combined$sdev^2    # Eigenvalues (Variances)


# 2. Visualize the Average Image -----------------------------------------------
# This will look like a mix of a 7 and a 9
par(mfrow=c(1,1))
digit.image(mu.comb)
title("Average Image of Combined Data (7 & 9)")


# 3. Visualize Synthetic Variations (5x5 Grid) ---------------------------------
# Shows how the "average blob" morphs into specific digits along PC axes
par(mfrow=c(5,5), mar=c(0.1, 0.1, 0.1, 0.1), oma=c(0, 2, 2, 0)) 

for (i in 1:5) {
  # Plot row using the helper function defined in Part 1(a)
  plot_pc_variation(i, pca.combined$sdev[i], mu.comb, evecs.comb)
  
  # Label the row
  mtext(paste("PC", i), side=2, line=0.5, outer=TRUE, 
        at=1 - (i-0.5)/5, las=1, cex=0.8)
}
mtext("Variations along PC 1-5 (Combined)", side=3, line=0.5, outer=TRUE)


# 4. Identify Typical and Atypical Images --------------------------------------
# "Typical" = Closest to the hybrid mean (Ambiguous)
# "Atypical" = Furthest from the hybrid mean (Distinct 7s or 9s)

# Calculate Euclidean distance from the center (0,0)
dist_comb <- sqrt(scores.comb[,1]^2 + scores.comb[,2]^2)

# Find indices
idx_typical_c <- order(dist_comb)[1:5]            # Smallest distance
idx_atypical_c <- order(dist_comb, decreasing=T)[1:5] # Largest distance

# Visualize (Green = Ambiguous/Typical, Red = Distinct/Atypical)
par(mfrow=c(2,5), mar=c(1,1,1,1))
for(i in idx_typical_c) {
  digit.image(data.train[i,])
  box(col="green", lwd=2)
}
mtext("Typical (Ambiguous)", side=3, line=-2, outer=TRUE)

for(i in idx_atypical_c) {
  digit.image(data.train[i,])
  box(col="red", lwd=2)
}
mtext("Atypical (Extreme)", side=3, line=-15, outer=TRUE)


# 5. Discrimination Scatterplot (PC1 vs PC2) -----------------------------------
# This is the "In addition" requirement - crucial for seeing separation

# Define colors: Red for 7, Blue for 9
my_colors <- ifelse(label.train == 7, "red", "blue")
my_pch <- ifelse(label.train == 7, 1, 4) # Circle vs Cross

par(mfrow=c(1,1))
plot(scores.comb[,1], scores.comb[,2],
     col = my_colors,
     pch = my_pch,
     xlab = "Principal Component 1",
     ylab = "Principal Component 2",
     main = "PCA Scores: Digit 7 (Red) vs. Digit 9 (Blue)",
     cex = 0.8)

# Add Legend and Grid
legend("topright", legend=c("Digit 7", "Digit 9"), 
       col=c("red", "blue"), pch=c(1, 4), bg="white")
grid()


# 6. Adequacy (Dual Scree Plots) -----------------------------------------------

# --- Plot A: The Elbow Method ---
par(mfrow=c(1,2)) 
barplot(evals.comb[1:30], main="Scree (Var) - Combined", names.arg=1:30, 
        col="gray", border=NA, ylab="Variance", xlab="PC #")
plot(evals.comb[1:30], type="b", pch=19, col="black",
     main="Scree (Elbow) - Combined", ylab="Variance", xlab="PC #")
grid()

```

```{r}
#LDA PART 2A 
# 1. Feature Selection (Filtering Low Variance Pixels) -------------------------
# As per sample code: calculate SD and keep only pixels with SD > 0.2
col.sd <- apply(data.train, 2, sd)
col.ind <- (1:256)[col.sd > 0.2] 

# 2. Train LDA Model -----------------------------------------------------------
# We use only the columns in 'col.ind'
lda.79 <- lda(data.train[, col.ind], grouping = label.train)

# 3. Visualize the LDA Coefficients --------------------------------------------
# Reconstruct the 256-pixel image from the scaling factors
LD1_vector <- rep(0, 256)
LD1_vector[col.ind] <- lda.79$scaling

# Plot the coefficient vector (The "Discriminator" Image)
par(mfrow=c(1,2))
digit.image(LD1_vector)
title("LDA Coefficient (Signed)")

# Plot absolute values (Shows importance regardless of sign)
digit.image(abs(LD1_vector))
title("LDA Coefficient (Magnitude)")

# ==============================================================================
# VISUAL COMPARISON: LDA vs. PCA (Part 2a Discussion)
# ==============================================================================

# 1. Get the LDA Vector (from Part 2a)
# (Assuming you already ran lda.79 in the previous step)
lda_vector <- rep(0, 256)
lda_vector[col.ind] <- lda.79$scaling

# 2. Get the PCA Vector (from Part 1c)
# We use the FIRST Principal Component (PC1) of the combined data
# pca.combined$rotation[,1] is the vector of weights for PC1
pca_vector <- pca.combined$rotation[,1]

# 3. Plot them Side-by-Side
par(mfrow=c(1,2))

# Plot LDA (The "Discriminator")
digit.image(lda_vector)
title("LDA Coefficient\n(Best for Separation)")

# Plot PCA (The "Describer")
digit.image(pca_vector)
title("PCA Eigenvector 1\n(Best for Variation)")


# 5. Calculate Error Rates (The "Evaluation" Step) -----------------------------

# --- A. Apparent Error Rate (Training Error) ---
# Predict classes for the training data
pred.train <- predict(lda.79, data.train[, col.ind])$class

# Confusion Matrix
table.train <- table(True = label.train, Predicted = pred.train)
cat("\nConfusion Matrix (Training):\n")
print(table.train)

# Calculate APER
aper <- mean(pred.train != label.train)
cat("Apparent Error Rate (Training):", round(aper, 4), "\n")

# --- B. Test Error Rate (Test Error) ---
# Predict classes for the test data
# IMPORTANT: Use the same columns (col.ind) for the test set!
pred.test <- predict(lda.79, data.test[, col.ind])$class

# Confusion Matrix
table.test <- table(True = label.test, Predicted = pred.test)
cat("\nConfusion Matrix (Test):\n")
print(table.test)

# Calculate TER
ter <- mean(pred.test != label.test)
cat("Test Error Rate (Test):", round(ter, 4), "\n")
```

```{r}
#LDA PART 2B 
# 1. Project the Test Data onto the PCA Space ----------------------------------
# We already have scores for Training Data (scores.comb) from Part 1c.
# We MUST project the Test Data using the SAME rotation/center from the Training PCA.
# predict() handles this automatically for prcomp objects.

scores.train <- scores.comb                # Training Scores (800 rows)
scores.test <- predict(pca.combined, newdata = data.test) # Test Scores (489 rows)


# 2. LDA using only the First 2 PCs (Comparison Step) --------------------------
# This corresponds to the Scatterplot in Part 1(c)

# Train LDA on just PC1 and PC2
lda.pca.2 <- lda(scores.train[, 1:2], grouping = label.train)

# Predict on Test Data
pred.test.pca.2 <- predict(lda.pca.2, scores.test[, 1:2])$class

# Calculate Error
ter.pca.2 <- mean(pred.test.pca.2 != label.test)
cat("Test Error Rate (Using 2 PCs):", round(ter.pca.2, 4), "\n")


# 3. Analyze Improvement: Loop through PC 2 to 50 ------------------------------
# Question: "Does the addition of subsequent PCs improve accuracy?"

# Define the range of PCs to test (Start at 2, go up to 50)
pc_range <- 2:50
error_rates <- numeric(length(pc_range)) # Placeholder for results

# Loop
for (i in 1:length(pc_range)) {
  k <- pc_range[i] # Current number of PCs (e.g., 2, 3, 4...)
  
  # Train LDA on first k PCs
  lda.temp <- lda(scores.train[, 1:k], grouping = label.train)
  
  # Predict on Test Data
  pred.temp <- predict(lda.temp, scores.test[, 1:k])$class
  
  # Calculate & Store Error Rate
  error_rates[i] <- mean(pred.temp != label.test)
}


# 4. Plot the Error Trend ------------------------------------------------------
par(mfrow=c(1,1))
plot(pc_range, error_rates, 
     type="o", pch=19, col="blue",
     xlab="Number of Principal Components",
     ylab="Test Error Rate",
     main="LDA Performance vs. Number of PCs",
     ylim=c(0, 0.25)) # Scale Y-axis to see improvement

# Add Reference Lines
grid()
# Comparison Line: The Error Rate from Raw Data (Part 2a)
# (Replace 'ter' with the variable name from Part 2a code, likely 'ter.raw' or 'ter')
abline(h=ter, col="red", lty=2, lwd=2) 
text(35, ter + 0.01, "Raw Data Error", col="red", pos=3)



# Print best result
min_error <- min(error_rates)
best_k <- pc_range[which.min(error_rates)]
cat("Minimum Test Error:", min_error, "achieved at", best_k, "PCs\n")

# ==============================================================================
# FINAL COMPARISON: Part 2(a) vs Part 2(b)
# ==============================================================================

# 1. Get Stats for Rule (a) - Raw Data -----------------------------------------
# (Assuming variables 'aper' and 'ter' are stored from Part 2a code)
# If not, just uncomment and manualy enter the numbers you got:
# aper_raw <- 0.0088
# ter_raw <- 0.0409
aper_raw <- aper  # From Part 2(a)
ter_raw <- ter    # From Part 2(a)


# 2. Get Stats for Rule (b) - Optimal PCA Model --------------------------------
# We found the best 'k' (best_k) and minimum test error (min_error) in Part 2(b).
# We just need to calculate the TRAINING error (APER) for that specific k to compare.

# Retrain LDA on the "Best" PCA model
lda.best.pca <- lda(scores.train[, 1:best_k], grouping = label.train)

# Predict on Training Data to get APER
pred.train.best <- predict(lda.best.pca, scores.train[, 1:best_k])$class
aper_pca <- mean(pred.train.best != label.train)

# We already have the Test Error (TER) from the loop
ter_pca <- min_error


# 3. Create the Comparison Table -----------------------------------------------
comparison_tab <- data.frame(
  Method = c("Rule (a): Raw Pixels (~182 vars)", paste("Rule (b): PCA (", best_k, " PCs)", sep="")),
  APER_Train = c(aper_raw, aper_pca),
  TER_Test = c(ter_raw, ter_pca)
)

# Print the table clearly
print(comparison_tab)


# 4. (Optional) Visualize the Difference ---------------------------------------
# A bar plot makes the "PCA wins" argument very visual
barplot(as.matrix(comparison_tab[,2:3]), beside=TRUE,
        col=c("red", "blue"),
        names.arg=c("Training Error", "Test Error"),
        main="Comparison of Classification Rules",
        ylab="Error Rate",
        ylim=c(0, 0.06)) # Zoom in on the low errors

legend("topright", legend=comparison_tab$Method, fill=c("red", "blue"))
grid()
```
